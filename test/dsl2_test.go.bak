package test

import (
	"bufio"
	"fmt"
	"io"
	"strings"
	"testing"

	"github.com/stretchr/testify/require"
)

type TokenType int

const (
	NUMBER TokenType = iota
	PLUS
	MINUS
	TIMES
	DIVIDE
	ASSIGN
	SEMICOLON
	LPAREN
	RPAREN
	COMMA
	VAR
	IF
	THEN
	END
	GREATER
	LESS
	EOF
)

type Token struct {
	Type  TokenType
	Value string
}

type Lexer struct {
	reader *bufio.Reader
}

func NewLexer(r io.Reader) *Lexer {
	return &Lexer{reader: bufio.NewReader(r)}
}

func (l *Lexer) NextToken() Token {
	var ch byte
	var err error
	for {
		ch, err = l.reader.ReadByte()
		if err!= nil {
			return Token{Type: EOF, Value: ""}
		}
		if ch ==' ' || ch == '\t' || ch == '\n' || ch == '\r' {
			continue
		}
		break
	}
	switch ch {
	case '+':
		return Token{Type: PLUS, Value: "+"}
	case '-':
		return Token{Type: MINUS, Value: "-"}
	case '*':
		return Token{Type: TIMES, Value: "*"}
	case '/':
		return Token{Type: DIVIDE, Value: "/"}
	case '=':
		return Token{Type: ASSIGN, Value: "="}
	case ';':
		return Token{Type: SEMICOLON, Value: ";"}
	case '(':
		return Token{Type: LPAREN, Value: "("}
	case ')':
		return Token{Type: RPAREN, Value: ")"}
	case ',':
		return Token{Type: COMMA, Value: ","}
	case '>':
		return Token{Type: GREATER, Value: ">"}
	case '<':
		return Token{Type: LESS, Value: "<"}
	case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		buf := strings.Builder{}
		buf.WriteByte(ch)
		for {
			ch, err = l.reader.ReadByte()
			if err!= nil {
				break
			}
			if ch == '+' || ch == '-' || ch == '*' || ch == '/' || ch ==' ' || ch == '\t' || ch == '\n' || ch == '\r' || ch == ';' || ch == '=' || ch == ',' || ch == '(' || ch == ')' || ch == '<' || ch == '>' {
				l.reader.UnreadByte()
				break
			}
			buf.WriteByte(ch)
		}
		return Token{Type: NUMBER, Value: buf.String()}
	case 'I':
		ch, err = l.reader.ReadByte()
		if err!= nil {
			return Token{Type: EOF, Value: ""}
		}
		if ch == 'F' {
			return Token{Type: IF, Value: "IF"}
		}
		l.reader.UnreadByte()
		return Token{Type: VAR, Value: "I"}
	case 'T':
		ch, err = l.reader.ReadByte()
		if err!= nil {
			return Token{Type: EOF, Value: ""}
		}
		if ch == 'H' {
			ch, err = l.reader.ReadByte()
			if err!= nil {
				return Token{Type: EOF, Value: ""}
			}
			if ch == 'E' {
				ch, err = l.reader.ReadByte()
				if err!= nil {
					return Token{Type: EOF, Value: ""}
				}
				if ch == 'N' {
					l.reader.UnreadByte()
					return Token{Type: THEN, Value: "THEN"}
				}
			}
			// not a THEN, ???
			l.reader.UnreadByte()
			return Token{Type: VAR, Value: "T"}
		}
	case 'E':
		ch, err = l.reader.ReadByte()
		if err!= nil {
			return Token{Type: EOF, Value: ""}
		}
		if ch == 'N' {
			ch, err = l.reader.ReadByte()
			if err != nil {
				return Token{Type: EOF, Value: ""}
			}
			if ch == 'D' {
				
			}
		}
		l.reader.UnreadByte()
		return Token{Type: VAR, Value: "E"}

	case 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'U', 'V', 'W', 'X', 'Y', 'Z':
		buf := strings.Builder{}
		buf.WriteByte(ch)
		for {
			ch, err = l.reader.ReadByte()

			if err!= nil {
				break
			}
			if ch == '+' || ch == '-' || ch == '*' || ch == '/' || ch ==' ' || ch == '\t' || ch == '\n' || ch == '\r' || ch == ';' || ch == '=' || ch == ',' || ch == '(' || ch == ')' || ch == '<' || ch == '>' {
				l.reader.UnreadByte()
				break
			}
			buf.WriteByte(ch)
		}
		return Token{Type: VAR, Value: buf.String()}
	
	default:
		fmt.Println("Unknown token: ", ch)
		return Token{Type: EOF, Value: ""}
	}
}
		


func TestLexer(t *testing.T) {
	require := require.New(t)
	lexer := NewLexer(strings.NewReader(`
		IF a > 0 THEN
			b = a + 1;
		END
	`))
	token := lexer.NextToken()
	require.Equal(IF, token.Type)
	require.Equal("IF", token.Value)
	token = lexer.NextToken()
	require.Equal(VAR, token.Type)
	require.Equal("a", token.Value)
	token = lexer.NextToken()
	require.Equal(GREATER, token.Type)	
	require.Equal(">", token.Value)
	token = lexer.NextToken()
	require.Equal(NUMBER, token.Type)
	require.Equal("0", token.Value)
	token = lexer.NextToken()
	require.Equal(THEN, token.Type)
	require.Equal("THEN", token.Value)
	token = lexer.NextToken()
	require.Equal(VAR, token.Type)
	require.Equal("b", token.Value)
	token = lexer.NextToken()
	require.Equal(ASSIGN, token.Type)
	require.Equal("=", token.Value)
	token = lexer.NextToken()
	require.Equal(VAR, token.Type)
	require.Equal("a", token.Value)
	token = lexer.NextToken()
	require.Equal(PLUS, token.Type)
	require.Equal("+", token.Value)
	token = lexer.NextToken()
	require.Equal(NUMBER, token.Type)
	require.Equal("1", token.Value)
	token = lexer.NextToken()
	require.Equal(SEMICOLON, token.Type)
	require.Equal(";", token.Value)
	token = lexer.NextToken()
	require.Equal(END, token.Type)
	require.Equal("END", token.Value)
	token = lexer.NextToken()
	require.Equal(EOF, token.Type)
	require.Equal("", token.Value)

}